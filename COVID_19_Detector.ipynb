{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID-19 Detector",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ptGyDxe9kZt"
      },
      "source": [
        "# command to download the dataset (covid_19) the specified URL\n",
        "!wget http://cb.lk/covid_19\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDHZhUXGBKGh"
      },
      "source": [
        "# unzipping the dataset : covid_19\n",
        "!unzip covid_19\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9jCFa1zBqF_"
      },
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras \n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukHeC9lTD2zI"
      },
      "source": [
        "# CNN based model using keras (with tensorflow backend)\n",
        "classifier = Sequential() # we have created an object(classifier:modle name) of class sequential() i.e we gonna add layer one by one\n",
        "## we are using conv2D layer\n",
        "## we are not using VGG layer because it works on around 180 million features so our model with very less dataset will definitely overfit\n",
        "classifier.add(Conv2D(32,kernel_size=(3,3),activation = 'relu',input_shape = (224,224,3)))\n",
        "classifier.add(Conv2D(64,(3,3),activation = 'relu'))\n",
        "# using 2 convolution layers of kernel size =(3,3) is similar to using one single convolution layer of kernal size =(5,5)\n",
        "# but we don't perfer that becauser to increase non linearity in the model using more relu funtions\n",
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "classifier.add(Dropout(0.25)) # to find overfitting in the model\n",
        "\n",
        "\n",
        "classifier.add(Conv2D(64,(3,3),activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "classifier.add(Dropout(0.25))\n",
        "\n",
        "classifier.add(Conv2D(128,(3,3),activation = 'relu'))\n",
        "# as we go deep into model we are increasing the number of convolutional layer because we are going to extract large size\n",
        "# features (i.e complex features)\n",
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "classifier.add(Dropout(0.25))\n",
        "\n",
        "classifier.add(Flatten());\n",
        "classifier.add(Dense(64,activation = 'relu'))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "classifier.compile(loss = keras.losses.binary_crossentropy,optimizer = 'adam',metrics =['accuracy'])\n",
        "# adam use gradient descent algorithm for optimizing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpyZQCN7KpTV",
        "outputId": "cd519a80-44af-4497-f911-39612c1cb2b4"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 220, 220, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 110, 110, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 110, 110, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 108, 108, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 54, 54, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 52, 52, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 86528)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                5537856   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 5,668,097\n",
            "Trainable params: 5,668,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu6ugFVLLizO"
      },
      "source": [
        "## training the model \n",
        "# firstly setting up the data ready for training i.e data preprocessing with the help of ImageDataGenerator\n",
        "train_datagen = image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True\n",
        ")\n",
        "validation_datagen = image.ImageDataGenerator(rescale = 1./255)\n",
        "# we are dividing by 255 for normalisation "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXj1-Yw3O_Fd",
        "outputId": "f4c0caba-6f6b-4124-f718-dc3b11cfe495"
      },
      "source": [
        "train_data = train_datagen.flow_from_directory('CovidDataset/Train',\n",
        "                                               target_size = (224,224),\n",
        "                                               batch_size = 32,\n",
        "                                               class_mode = 'binary')\n",
        "# here images get loaded one by one and get reshaped to specified dimensions\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 224 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGIk7BXnQcnr",
        "outputId": "036056cd-0ebc-4849-b899-487ab06e5839"
      },
      "source": [
        "train_data.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Covid': 0, 'Normal': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpgMh-6-S-LM",
        "outputId": "e98acc44-51d6-4746-96c4-cab9f83d578d"
      },
      "source": [
        "validation_data = validation_datagen.flow_from_directory('CovidDataset/Val',\n",
        "                                               target_size = (224,224),\n",
        "                                               batch_size = 32,\n",
        "                                            class_mode = 'binary')\n",
        "# here images get loaded one by one and get reshaped to specified dimensions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 60 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SavLvWMDUWZZ",
        "outputId": "d1deeb0b-d1d3-4ec7-d0ac-95dfcf7ec4dc"
      },
      "source": [
        "validation_data.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Covid': 0, 'Normal': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZalsN96Uk7x",
        "outputId": "e056abd4-f7ef-4739-9e66-a5e6e4f4b092"
      },
      "source": [
        "final_model = classifier.fit_generator(train_data,\n",
        "                          steps_per_epoch= 7,\n",
        "                         epochs = 10,\n",
        "                         validation_data = validation_data,\n",
        "                         validation_steps = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 60s 2s/step - loss: 2.4544 - accuracy: 0.5109 - val_loss: 0.6887 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.6694 - accuracy: 0.5805 - val_loss: 0.6588 - val_accuracy: 0.9333\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.6194 - accuracy: 0.6369 - val_loss: 0.5063 - val_accuracy: 0.8833\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.4704 - accuracy: 0.7643 - val_loss: 0.4836 - val_accuracy: 0.8500\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.3884 - accuracy: 0.8215 - val_loss: 0.1925 - val_accuracy: 0.9667\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.2847 - accuracy: 0.8927 - val_loss: 0.2570 - val_accuracy: 0.9667\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 10s 2s/step - loss: 0.3579 - accuracy: 0.8288 - val_loss: 0.1486 - val_accuracy: 0.9833\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.3073 - accuracy: 0.8699 - val_loss: 0.1256 - val_accuracy: 0.9667\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.1903 - accuracy: 0.9034 - val_loss: 0.0952 - val_accuracy: 0.9667\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.1394 - accuracy: 0.9562 - val_loss: 0.0628 - val_accuracy: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRONbyBFeyDx"
      },
      "source": [
        "## with help of \"grad CAM\" technique we can see and visualize how our model is differentiating the features i.e on which \n",
        "## part of network our model is focusing on cilensing map\n",
        "## can read about class activation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InEuckHlj5Ym"
      },
      "source": [
        "## saving the model\n",
        "classifier.save(\"COVID_19_model.h5\")\n",
        "##Through Keras, models can be saved in three formats:\n",
        "#YAML format\n",
        "#JSON format\n",
        "#HDF5 format\n",
        "#YAML and JSON files store only model structure, whereas, HDF5 file stores complete neural network model along with structure and weights. Therefore, if the model structure is saved using YAML or JSON format, weights should be stored in an HDF5 file to store the entire model."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYejnf6-nK_X"
      },
      "source": [
        "# we can load the model when ever required\n",
        "classifier = load_model(\"COVID_19_model.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZUzC2Wenj9D"
      },
      "source": [
        "import os  # it is a standard library in python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw0j5FJpZ27y",
        "outputId": "eca48ab7-6b7b-4b49-9546-0a8e88ee459f"
      },
      "source": [
        "# setup for confusion matrix\n",
        "y_validation = []\n",
        "y_predict = []\n",
        "for i in os.listdir(\"./CovidDataset/Val/Normal/\"):\n",
        "  img = image.load_img(\"./CovidDataset/Val/Normal/\"+i,target_size = (224,224))\n",
        "  img = image.img_to_array(img)\n",
        "  img = np.expand_dims(img,axis = 0)\n",
        "  pred = classifier.predict_classes(img)\n",
        "  y_predict.append(pred[0,0])\n",
        "  y_validation.append(1)\n",
        "for i in os.listdir(\"./CovidDataset/Val/Covid/\"):\n",
        "  img = image.load_img(\"./CovidDataset/Val/Covid/\"+i,target_size = (224,224))\n",
        "  img = image.img_to_array(img)\n",
        "  img = np.expand_dims(img,axis = 0)\n",
        "  pred = classifier.predict_classes(img)\n",
        "  y_predict.append(pred[0,0])\n",
        "  y_validation.append(0)\n",
        "y_validation = np.array(y_validation)\n",
        "y_predict = np.array(y_predict)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOc5rq4PdYR-"
      },
      "source": [
        "# now importing sklearn for confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# sklearn provides a selection of efficient tools for machine learning and statistical modeling \n",
        "#including classification, regression, clustering and dimensionality reduction via a consistence interface in Python.\n",
        "\n",
        "con_matrix = confusion_matrix(y_validation,y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "m5RsNGHHflaW",
        "outputId": "f99f5adf-cbdc-449b-df3e-0fb5aedf9dc6"
      },
      "source": [
        "import seaborn as sns\n",
        "#Seaborn is an open-source Python library built on top of matplotlib. \n",
        "#It is used for data visualization and exploratory data analysis. \n",
        "#Seaborn works easily with dataframes and the Pandas library.\n",
        "\n",
        "sns.heatmap(con_matrix,cmap = \"ocean_r\",annot = True)\n",
        "# Heatmap is defined as a graphical representation of data using colors to visualize the value of the matrix\n",
        "# cmap is for color map (ex : ocean, ocean_r, pink, pink_r, plasma )\n",
        "# annot : When we pass bool ‘True‘ value to annot then the value will show on each cell of the heatmap."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa815153890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0thkTfRgPBk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}